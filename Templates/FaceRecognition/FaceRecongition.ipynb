{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition\n",
    "\n",
    "Face recognition algorithms depend on comparing a single sampled image to a large database to find the closest match. With a large database, it is not practical to compare each image one-on-one. One solution is to consider each image as a vector in a very high-dimensional vector space. The database is used to generate a basis for this vector space of all faces in such a way that the dimensions of the vector space may be compressed or flattened.  \n",
    "\n",
    "As an example, think of a dataset consisting of many points with coordinates in three dimensions, but which all fall nearly, but not quite,  on a single plane in space. These points are in three dimensions, but we can reasonably approximate them by only two dimensions. To do this, we think of the points as vectors and find two perpendicular unit (orthonormal) vectors on that plane. These vectors are a basis for this subspace (ie the plane within 3-d space). Any point  can be expresses as just two numbers, it's coordinated on that plane. A point's coordinates are found by projecting the vector representing it onto the coordinate vectors.\n",
    "\n",
    "In this exercise, we will use this idea to project an image onto basis vectors to get its coordinates in the image data base. We will find that the basis vectors are a much smaller set than the full dataset, allowing a very efficient means of processing images.\n",
    "\n",
    "For face recognition and image processing, if you have a database of thousands of images, there aren't really thousands dimensions of variability among the faces, and the database can be reduced to a small set of basis images that explain the important differences among the images. If we treat the images as vectors, they are actually members of a small subspace spanned by our  basis images. Here, we will construct these basis images as the eigenvectors of the covariance matrix computed from the images. These details are not important, only that we have a set of basis images that describe the dataset.\n",
    "\n",
    "The dataset consists of 40 Faces (fig below) and 39 \"EigenFaces\" (fig below). The eigenfaces were computed using only 39 faces, leaving one out for validation. You can see from the EigenFaces  that the first few contain a lot more information and we can likely ignore about half of the EigenFaces, which compresses the vector space to something like 10-20 dimensions.\n",
    "\n",
    "We can consider each face as a vector with dimensions equal to the number of pixels in the image, 96x64=6144. However, in practice, the faces all live in a subspace spanned by the 39 eigen vectors. This 39-dimensional space in turn, is very \"flat\" (like a pancake in 3-D) and can be approximated by something like 20 dimensions, the first 20 eigenvectors.\n",
    "\n",
    "Read the code so you understand how it works. Change some of the options. The script will plot the coordinates of the selected faces in the basis of EigenFaces; you can see how the coordinates become quite small for higher numbered EigenFaces, showing that the vector space is flattened.\n",
    "\n",
    "The script does 3 tasks: 1) Reconsruct an image in the training set (used to compute the EigenFace basis) using a small number of EigenFaces (try 10 or 20 )  2) Reconstruct an messed up image, like might be captured with a web cam. 3) Reconsruct an unknown image (not used to compute the EigenFace basis) using a small number of EigenFaces (try 10 or 20 or even all 39 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 186,
     "status": "ok",
     "timestamp": 1646163859565,
     "user": {
      "displayName": "Eric P. Salathe",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GglgPR1DRkbgcLfd3WBQnn1V5TCvs-9B2amF2CQ=s64",
      "userId": "05199657044909295070"
     },
     "user_tz": 480
    },
    "id": "TZls8kQY8YOm"
   },
   "outputs": [],
   "source": [
    "# Face recognition by Santiago Serrano\n",
    "# http://www.pages.drexel.edu/~sis26/Eigencode.htm\n",
    "# Modified by Eric Salathe \n",
    "from numpy import (\n",
    "    linspace,array,zeros,log,exp,sin,cos,sqrt,pi,e, \n",
    "    ones, arange, zeros, real, imag, sign, shape, dot, size,\n",
    "    mean\n",
    "    )\n",
    "\n",
    "from numpy.random import rand\n",
    "\n",
    "from matplotlib.pyplot import (\n",
    "    plot,xlabel,ylabel,legend,show, figure, subplot, title, tight_layout, stem, pcolormesh,\n",
    "    get_cmap\n",
    "    )   \n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the image database\n",
    "This fills an 96x64x40  array called  pics where each 96x64 layer is a\n",
    "picture and there are 40 pictures (layers). \n",
    "The first pictur is pics[:,:,0]\n",
    "To make  picture number i into a single column vector, use\n",
    "X=pics[:,:,i].reshape((row*col,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "executionInfo": {
     "elapsed": 569,
     "status": "error",
     "timestamp": 1646163865596,
     "user": {
      "displayName": "Eric P. Salathe",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GglgPR1DRkbgcLfd3WBQnn1V5TCvs-9B2amF2CQ=s64",
      "userId": "05199657044909295070"
     },
     "user_tz": 480
    },
    "id": "80N77NrI_oSw",
    "outputId": "6c348f36-6e0c-40d8-fa4a-b6d5cc37abb7"
   },
   "outputs": [],
   "source": [
    "# read in images\n",
    "\n",
    "infile=loadmat('Faces.mat')\n",
    "pics = infile['pics']\n",
    "\n",
    "row, col, mpictot = shape(pics) # image size\n",
    "npixel = row*col # total pixels in each image\n",
    "\n",
    "print('Read in ',mpictot,' images')\n",
    "print('Each image contains ',npixel,' pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the EigenFaces\n",
    "\n",
    "The set of eigen faces $\\vec u_i$  form a basis for our\n",
    "vector space of faces. Only the top few eigenfaces are necesary\n",
    "to represent the dataset, and we can flatten the vector space -- reduce it's dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "executionInfo": {
     "elapsed": 569,
     "status": "error",
     "timestamp": 1646163865596,
     "user": {
      "displayName": "Eric P. Salathe",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GglgPR1DRkbgcLfd3WBQnn1V5TCvs-9B2amF2CQ=s64",
      "userId": "05199657044909295070"
     },
     "user_tz": 480
    },
    "id": "80N77NrI_oSw",
    "outputId": "6c348f36-6e0c-40d8-fa4a-b6d5cc37abb7"
   },
   "outputs": [],
   "source": [
    "infile=loadmat('EigenFaces.mat')\n",
    "u=infile['u']\n",
    "nn, meig = shape(u) # meig is the number of eigen vectors in our basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Atlas\n",
    "\n",
    "### Image database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the faces, 5 to a row\n",
    "\n",
    "fig=figure(1, figsize=[8,16])\n",
    "cmap=get_cmap('gray')\n",
    "figcol=5\n",
    "figrow=int(mpictot/figcol)\n",
    "for i in range(mpictot):\n",
    "    subplot(figrow, figcol, i+1)\n",
    "    pcolormesh(pics[:,:,i],cmap=cmap)\n",
    "fig.suptitle('Face Database')\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigen Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the eigen faces, 5 to a row\n",
    "\n",
    "fig=figure(2, figsize=[8,16])\n",
    "for i in range(meig):\n",
    "    subplot(figrow, figcol, i+1)\n",
    "    pcolormesh(u[:,i].reshape((row,col),order='F'),cmap=cmap)\n",
    "fig.suptitle('Eigen Faces')\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Reconstruct an image in the training set using a reduced basis\n",
    "\n",
    "In this part, selet an image $\\vec x$ from the training data and see how many eigenfaces are necesary to reproduce the image.\n",
    "\n",
    "To reconstruct the image we sum over each eigenvector (ie columns of u(:,i)) after multiplying by\n",
    "the appropriate coordinate value (coord). The coordinates are found from taking the dot product between the face ($\\vec x$) and the eigenfaces:\n",
    "\n",
    "$$\n",
    "\\vec{X}_{rec} = \\sum_{i=1}^{n} \\sigma_i\\vec{u}_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_i = \\vec{x} \\cdot \\vec{u}_i\n",
    "$$\n",
    "\n",
    "Xrec = sig(1)*u(1) + sig(2)*u(2) + ... + sig(n)*u(n)\n",
    "\n",
    "where sig(i) are the coordinates and u(i) are the eigenvectors\n",
    "but we use a for loop to do this in python.\n",
    "\n",
    "You can change the selected image (i_img) and number of eigenfaces for reconstruction (m_rec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVJmG9-t_q6m"
   },
   "outputs": [],
   "source": [
    "# Select an image from the training set onto eigen vectors\n",
    "i_img = 2 # select an arbitrary image\n",
    "m_rec =  15 # number of images to use for reconstruction < meig. try 10 <= m_rec <= 20\n",
    "\n",
    "\n",
    "######### Don't change below here #############\n",
    "\n",
    "picture = pics[:,:,i_img]\n",
    "\n",
    "# put the face into a vector\n",
    "X = picture.reshape((row*col,),order='F')\n",
    "\n",
    "# get the coordinates of this face in our eigenvector space using the dot prodcuct (dot(a,b) in numpy)\n",
    "#         sig_i = X•u_i\n",
    "\n",
    "sig=zeros(meig)\n",
    "### Create a for loop and compute each sig[i]\n",
    "for i in range(meig):\n",
    "    sig[i] = dot(X, u[:,i])\n",
    "\n",
    "\n",
    "# Loop and sum over the eigenvalues\n",
    "Xrec = zeros(size(X)) # all zeros and size of the original vector\n",
    "### Create a for loop and sum to get Xrec\n",
    "for i in range(m_rec):\n",
    "    Xrec = Xrec + sig[i]*u[:,i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Note that if we were to take the above sum for m_rec=mpic, we'd be\n",
    "# exactly inverting the computation in the earlier loop that computs the\n",
    "# coordinates. By truncating the sum to fewer terms, we get an approximation. \n",
    "\n",
    "\n",
    "# plot the image coordinates\n",
    "figure(1)\n",
    "\n",
    "ll = arange(meig)\n",
    "stem(ll,sig) # this makes a \"stem plot\"\n",
    "title('Weight of Input Face') # ,'fontsize',14)\n",
    "\n",
    "# draw the face\n",
    "figure(2)\n",
    "subplot(1,2,1)\n",
    "cmap=get_cmap('gray')\n",
    "pcolormesh(picture,cmap=cmap) \n",
    "\n",
    "# draw the reconstructed image.\n",
    "subplot(1,2,2)\n",
    "pcolormesh(Xrec.reshape((row,col),order='F'),cmap=cmap) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Reconstruct a messed-up image \n",
    "\n",
    "Now we will add noise to the image and see if we can still reconstruct it. This is like recognizing and image in our training data given a poor quality or slightly different image.\n",
    "\n",
    "You can adjust the noise level and the number of eigenfaces for reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_0Kbz7wS_0kq"
   },
   "outputs": [],
   "source": [
    "# Select an image and add some random speckle of specified amplitude\n",
    "\n",
    "i_img = 2 # seclect an arbitrart image\n",
    "m_rec =  15 # number of images to use for reconstruction < meig. try 10 <= m_rec <= 20\n",
    "noiselevel=2 # the magnitude of the noise relative to average; try different values\n",
    "\n",
    "######### Don't change below here #############\n",
    "\n",
    "picture = pics[:,:,i_img] + rand(row,col) * noiselevel*mean(pics[:,:,i_img]) \n",
    "\n",
    "# put the face into a vector\n",
    "X = picture.reshape((row*col,),order='F')\n",
    "\n",
    "# get the coordinates of this face in our eigenvector space using the dot prodcuct (dot(a,b) in numpy)\n",
    "#         sig_i = X•u_i\n",
    "\n",
    "sig=zeros(meig)\n",
    "### Create a for loop and compute each sig[i]\n",
    "for i in range(meig):\n",
    "    sig[i] = dot(X, u[:,i])\n",
    "\n",
    "\n",
    "# Loop and sum over the eigenvalues\n",
    "Xrec = zeros(size(X)) # all zeros and size of the original vector\n",
    "### Create a for loop and sum to get Xrec\n",
    "for i in range(m_rec):\n",
    "    Xrec = Xrec + sig[i]*u[:,i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Note that if we were to take the above sum for m_rec=mpic, we'd be\n",
    "# exactly inverting the computation in the earlier loop that computs the\n",
    "# coordinates. By truncating the sum to fewer terms, we get an approximation. \n",
    "\n",
    "\n",
    "# plot the image coordinates\n",
    "figure(1)\n",
    "\n",
    "ll = arange(meig)\n",
    "stem(ll,sig) # this makes a \"stem plot\"\n",
    "title('Weight of Input Face') # ,'fontsize',14)\n",
    "\n",
    "# draw the face\n",
    "figure(2)\n",
    "subplot(1,2,1)\n",
    "cmap=get_cmap('gray')\n",
    "pcolormesh(picture,cmap=cmap) \n",
    "\n",
    "# draw the reconstructed image.\n",
    "subplot(1,2,2)\n",
    "pcolormesh(Xrec.reshape((row,col),order='F'),cmap=cmap) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de4IErI3_1kS"
   },
   "source": [
    "## 3 Reconstruct an image not included in the training data\n",
    "i_img=39 was not used for computing the eigen values u\n",
    "see what happens if you use this image. Will any number of eigen faces reconstruct the image? What does that say about trying to identify a face when it is not in the database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 178,
     "status": "ok",
     "timestamp": 1646163882446,
     "user": {
      "displayName": "Eric P. Salathe",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GglgPR1DRkbgcLfd3WBQnn1V5TCvs-9B2amF2CQ=s64",
      "userId": "05199657044909295070"
     },
     "user_tz": 480
    },
    "id": "FqX_QxAvA10y",
    "outputId": "c7d58cb3-2e51-4d0e-e989-82d73a9985d3"
   },
   "outputs": [],
   "source": [
    "# Select an image from the training set onto eigen vectors\n",
    "i_img = 39 # select an arbitrary image\n",
    "m_rec =  15 # number of images to use for reconstruction < meig. try 10 <= m_rec <= 20\n",
    "\n",
    "\n",
    "######### Don't change below here #############\n",
    "\n",
    "picture = pics[:,:,i_img]\n",
    "\n",
    "# put the face into a vector\n",
    "X = picture.reshape((row*col,),order='F')\n",
    "\n",
    "# get the coordinates of this face in our eigenvector space using the dot prodcuct (dot(a,b) in numpy)\n",
    "#         sig_i = X•u_i\n",
    "\n",
    "sig=zeros(meig)\n",
    "### Create a for loop and compute each sig[i]\n",
    "for i in range(meig):\n",
    "    sig[i] = dot(X, u[:,i])\n",
    "\n",
    "\n",
    "# Loop and sum over the eigenvalues\n",
    "Xrec = zeros(size(X)) # all zeros and size of the original vector\n",
    "### Create a for loop and sum to get Xrec\n",
    "for i in range(m_rec):\n",
    "    Xrec = Xrec + sig[i]*u[:,i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Note that if we were to take the above sum for m_rec=mpic, we'd be\n",
    "# exactly inverting the computation in the earlier loop that computs the\n",
    "# coordinates. By truncating the sum to fewer terms, we get an approximation. \n",
    "\n",
    "\n",
    "# plot the image coordinates\n",
    "figure(1)\n",
    "\n",
    "ll = arange(meig)\n",
    "stem(ll,sig) # this makes a \"stem plot\"\n",
    "title('Weight of Input Face') # ,'fontsize',14)\n",
    "\n",
    "# draw the face\n",
    "figure(2)\n",
    "subplot(1,2,1)\n",
    "cmap=get_cmap('gray')\n",
    "pcolormesh(picture,cmap=cmap) \n",
    "\n",
    "# draw the reconstructed image.\n",
    "subplot(1,2,2)\n",
    "pcolormesh(Xrec.reshape((row,col),order='F'),cmap=cmap) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocpx8m5jA2-U"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP8QQOqN0I+XlEXmb8shcoY",
   "name": "FaceRecongition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
